{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\b34b3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pybullet_data\n"
     ]
    }
   ],
   "source": [
    "import pybullet_data\n",
    "import pybullet as p\n",
    "import pybullet_industrial as pi\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "p.connect(p.GUI)  # Use p.DIRECT for headless\n",
    "#p.connect(p.DIRECT)\n",
    "data_path = pybullet_data.getDataPath()\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "print(pybullet_data.getDataPath())\n",
    "plane_id = p.loadURDF(\"plane.urdf\")\n",
    "\n",
    "# Get the path to the PyBullet data directory\n",
    "data_path = pybullet_data.getDataPath()\n",
    "\n",
    "# List the files in the PyBullet data directory\n",
    "files = os.getcwd()\n",
    "dirname = os.path.join(files,'robots')\n",
    "assets = os.path.join(files,'assets')\n",
    "\n",
    "urdf_file1 = os.path.join(dirname,'rb5_850e.urdf')\n",
    "asset1 = os.path.join(assets,'specimen.urdf')\n",
    "#endeffector = os.path.join(assets,'endeffector.urdf')\n",
    "endeffector = os.path.join(assets,\n",
    "                                'gripper_cylinder.urdf')\n",
    "\n",
    "start_orientation = p.getQuaternionFromEuler([0, 0, 0])\n",
    "\n",
    "cube1 = p.loadURDF(\"cube.urdf\", np.array(\n",
    "        [0, 0, 0.5]), useFixedBase=True)\n",
    "robot = pi.RobotBase(urdf_file1, np.array(\n",
    "        [0, 0, 1]), start_orientation)\n",
    "cube2 = p.loadURDF(\"cube.urdf\", np.array(\n",
    "        [1, 0, 0.5]), useFixedBase=True)\n",
    "specimen = p.loadURDF(asset1, np.array(\n",
    "[1.0, 0, 1.3]), useFixedBase=True)\n",
    "meshScale = [1, 1, 1]\n",
    "\n",
    "pi.draw_robot_frames(robot, life_time=0)\n",
    "\n",
    "tool = pi.EndeffectorTool(endeffector, np.array([2.0, 0, 1.5]), start_orientation, robot)\n",
    "p.setGravity(0, 0, -9.81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    position_list = [1,0.16175214925291828,0.49468914613294146,1.4254185043970449,-0.350008612250527,1.5717769960272012,-0.1634941307782464,0]\n",
    "    gripper_position = [0.5, 0, 1.1]\n",
    "    gripper_orientation = [1, 1, 1, 1]\n",
    "    #update_gripper(gripper_position, gripper_orientation)\n",
    "\n",
    "    pose_dict = {\n",
    "    \"base\": 0.16175214925291828,\n",
    "    \"shoulder\": 0.49468914613294146,\n",
    "    \"elbow\": 1.4254185043970449,\n",
    "    \"wrist1\": -0.3500086122505276,\n",
    "    \"wrist2\": 1.5717769960272012,\n",
    "    \"wrist3\": -0.1634941307782464\n",
    "\n",
    "    }\n",
    "\n",
    "    pi.RobotBase.reset_robot(robot,[0, 0, 1], start_orientation, position_list)\n",
    "    pi.RobotBase.set_joint_position(robot,pose_dict)\n",
    "    for i in range(1000):\n",
    "      p.stepSimulation()\n",
    "\n",
    "def check_collision(visualize=False):\n",
    "    contacts = p.getContactPoints() \n",
    "    contacts = [c for c in contacts if c[1] >= 4] # 로봇의 베이스나, 엔드이펙터와 플랜지사이의 충돌은 무시\n",
    "    if contacts:\n",
    "        print(\"TCP 링크가 무언가와 충돌 발생!\")\n",
    "        for contact in contacts:\n",
    "            print(contact)\n",
    "    \n",
    "    if visualize:\n",
    "        for c in contacts:\n",
    "            pos_onB = c[6]\n",
    "            p.removeAllUserDebugItems()\n",
    "            p.addUserDebugPoints(\n",
    "                pointPositions=[pos_onB],\n",
    "                pointColorsRGB=[[1, 0, 0]],   # 빨간색\n",
    "                pointSize=50,\n",
    "                lifeTime=10\n",
    "            )\n",
    "\n",
    "def update_camera(camera_position, camera_orientation):\n",
    "    camera_id = None\n",
    "    for body_id in range(p.getNumBodies()):\n",
    "        body_name = p.getBodyInfo(body_id)[1].decode()\n",
    "        if \"camera\" in body_name:  # 카메라 URDF 파일명이 포함된 경우\n",
    "            camera_id = body_id\n",
    "            break\n",
    "    pos_offset = np.array([0.1, 0, 0.04])\n",
    "    ori_offset = np.array([0.5, 0.5, 0, 0])\n",
    "    p.resetBasePositionAndOrientation(camera_id, camera_position + pos_offset, camera_orientation + ori_offset)\n",
    "\n",
    "def update_specimen(specimen_position, specimen_orientation):\n",
    "    specimen_id = None\n",
    "    for body_id in range(p.getNumBodies()):\n",
    "        body_name = p.getBodyInfo(body_id)[1].decode()\n",
    "        if \"my_specimen\" in body_name:  # my_specimen URDF 파일명이 포함된 경우\n",
    "            specimen_id = body_id\n",
    "            break\n",
    "    p.resetBasePositionAndOrientation(specimen_id, specimen_position, specimen_orientation)\n",
    "\n",
    "def update_gripper(gripper_position, gripper_orientation):\n",
    "    gripper_id = None\n",
    "    for body_id in range(p.getNumBodies()):\n",
    "        body_name = p.getBodyInfo(body_id)[1].decode()\n",
    "        if \"gripper\" in body_name:  # gripper URDF 파일명이 포함된 경우\n",
    "            gripper_id = body_id\n",
    "            break\n",
    "    p.resetBasePositionAndOrientation(gripper_id, gripper_position, gripper_orientation)\n",
    "\n",
    "def show_point(tool_pos):\n",
    "    p.addUserDebugPoints(\n",
    "    pointPositions=[tool_pos],\n",
    "    pointColorsRGB=[[1, 0, 1]],  \n",
    "    pointSize=10,\n",
    "    lifeTime=1\n",
    ")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize()\n",
    "\n",
    "urdf_file3 = os.path.join(assets, 'camera.urdf')\n",
    "camera_parameters = {'width': 480, 'height': 240, 'fov': 60,\n",
    "                        'aspect ratio': 1, 'near plane distance': 0.01, 'far plane distance': 2}\n",
    "camera_orientation = p.getQuaternionFromEuler([1.57, 0, 1.57])\n",
    "camera_position = tool.get_tool_pose()[0] +  np.array([0, 0, 0.1])\n",
    "camera = pi.Camera(urdf_file3, camera_position,\n",
    "                camera_orientation, camera_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pose = np.array([0, 0, 0.5])\n",
    "set_pose = np.array([0.700, 0, 0.81])\n",
    "base_orientation = np.array([1.57, 0, 1.57])\n",
    "\n",
    "target_pose = base_pose + set_pose\n",
    "\n",
    "\n",
    "specimen_position = np.array([1.0, 0, 1.30])\n",
    "ring_offset = np.array([0, 0, 0.015])\n",
    "specimen_orientation_euler = np.array([0, 0, 0])\n",
    "specimen_orientation = p.getQuaternionFromEuler(specimen_orientation_euler)\n",
    "update_specimen(specimen_position, specimen_orientation)\n",
    "\n",
    "for _ in range(24 * 1):  # 240 Hz simulation frequency\n",
    "    tool.set_tool_pose(target_pose, p.getQuaternionFromEuler(base_orientation))\n",
    "    img = camera.get_image()\n",
    "    p.stepSimulation()\n",
    "    camera_orientation = p.getQuaternionFromEuler([1.57, 0, 1.57])\n",
    "    camera_position = tool.get_tool_pose()[0] +  np.array([0, 0, 0])\n",
    "    update_camera(camera_position, camera_orientation)\n",
    "    show_point(tool.get_tool_pose()[0]+np.array([0.135,0,0]))\n",
    "    show_point(specimen_position+ring_offset)\n",
    "    #time.sleep(1./24.)\n",
    "\n",
    "check_collision(visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_model_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_model_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_states        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ input_states[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93184</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">23,855,360</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_action_matri… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_advantages    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,084</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_states        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m480\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m119\u001b[0m,   │      \u001b[38;5;34m6,176\u001b[0m │ input_states[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m58\u001b[0m,    │     \u001b[38;5;34m32,832\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93184\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │ \u001b[38;5;34m23,855,360\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_action_matri… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m12\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_advantages    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │      \u001b[38;5;34m3,084\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,934,380</span> (91.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,934,380\u001b[0m (91.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,934,380</span> (91.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,934,380\u001b[0m (91.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_states (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93184</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,855,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_states (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m480\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m119\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m32,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93184\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m23,855,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,931,553</span> (91.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,931,553\u001b[0m (91.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,931,553</span> (91.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,931,553\u001b[0m (91.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.client import device_lib\n",
    "import gym\n",
    "import numpy as np\n",
    "import random as rand\n",
    "\n",
    "LOSS_CLIPPING = 0.2\n",
    "\n",
    "class ModelParam:\n",
    "    pass\n",
    "\n",
    "def AI_init():\n",
    "    model_param = ModelParam()\n",
    "    # state and action space\n",
    "    model_param.state_size = 4     # [pos,vel,angle,angular_vel] \n",
    "    model_param.img_height = 240\n",
    "    model_param.img_width = 480\n",
    "    model_param.img_channels = 3\n",
    "    model_param.action_size = 12   # [x+,x-,y+,y-,z+,z-,roll+,roll-,pitch+,pitch-,yaw+,yaw-]\n",
    "    model_param.value_size = 1\n",
    "\n",
    "    # AI hyperparameters\n",
    "    model_param.learning_rate_actor = 0.0005\n",
    "    model_param.learning_rate_critic = 0.0005\n",
    "    model_param.epochs_cnt = 5\n",
    "    model_param.discount_rate = 0.98\n",
    "    model_param.smooth_rate = 0.95\n",
    "    model_param.penalty = -400\n",
    "    model_param.episode_num = 500\n",
    "    model_param.mini_batch_step_size = 32        \n",
    "    model_param.node_num = 256     # used after flatten\n",
    "\n",
    "    # Debug variables\n",
    "    model_param.moving_avg_size = 20\n",
    "\n",
    "    # model Initialization\n",
    "    model_param.model_actor = build_model_actor(model_param)\n",
    "    model_param.model_critic = build_model_critic(model_param)\n",
    "\n",
    "    # reward buffer\n",
    "    model_param.reward_list= []\n",
    "    model_param.count_list = []\n",
    "    model_param.moving_avg_list = []\n",
    "\n",
    "    model_param.states, model_param.states_next, model_param.action_matrixs = state =np.zeros(4),[],[]\n",
    "    model_param.dones, model_param.action_probs, model_param.rewards = [],[],[]\n",
    "\n",
    "    # dummy data\n",
    "    model_param.DUMMY_ACTION_MATRIX = np.zeros((1,1,model_param.action_size))\n",
    "    model_param.DUMMY_ADVANTAGE = np.zeros((1,1,model_param.value_size))\n",
    "    return model_param\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "        def train_step(self, data):\n",
    "            in_datas, out_action_probs = data\n",
    "            states, action_matrixs, advantages = in_datas[0], in_datas[1], in_datas[2]\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = self(states, training=True)\n",
    "                new_policy = K.max(action_matrixs*y_pred, axis=-1)   \n",
    "                old_policy = K.max(action_matrixs*out_action_probs, axis=-1)   \n",
    "                r = new_policy/(old_policy + 1e-10)\n",
    "                clipped = K.clip(r, 1-LOSS_CLIPPING, 1+LOSS_CLIPPING)\n",
    "                loss = -K.minimum(r*advantages, clipped*advantages)\n",
    "            \n",
    "            trainable_vars = self.trainable_variables\n",
    "            gradients = tape.gradient(loss, trainable_vars)\n",
    "            self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "def build_model_actor(model_param):\n",
    "     # 1) The main input: an RGB image\n",
    "    input_states = Input(shape=(model_param.img_height, model_param.img_width, model_param.img_channels),\n",
    "                         name='input_states')\n",
    "\n",
    "    # 2) Additional inputs (same as your old code):\n",
    "    input_action_matrixs = Input(shape=(1, model_param.action_size), name='input_action_matrixs')\n",
    "    input_advantages = Input(shape=(1, model_param.value_size), name='input_advantages')\n",
    "\n",
    "    # 3) Build a small CNN\n",
    "    x = Conv2D(32, kernel_size=8, strides=4, activation='relu')(input_states)\n",
    "    x = Conv2D(64, kernel_size=4, strides=2, activation='relu')(x)\n",
    "    x = Conv2D(64, kernel_size=3, strides=1, activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(model_param.node_num, activation='relu')(x)\n",
    "\n",
    "    # 4) Output: policy over model_param.action_size\n",
    "    out_actions = Dense(model_param.action_size, activation='softmax', name='output')(x)\n",
    "\n",
    "    # 5) Create a MyModel with multi-input\n",
    "    model = MyModel(inputs=[input_states, input_action_matrixs, input_advantages],\n",
    "                    outputs=out_actions)\n",
    "    model.compile(optimizer=Adam(learning_rate=model_param.learning_rate_actor))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def build_model_critic(model_param):\n",
    "    # Takes image input: (height, width, channels)\n",
    "    input_states = Input(shape=(model_param.img_height, model_param.img_width, model_param.img_channels),\n",
    "                         name='input_states')\n",
    "\n",
    "    x = Conv2D(32, kernel_size=8, strides=4, activation='relu')(input_states)\n",
    "    x = Conv2D(64, kernel_size=4, strides=2, activation='relu')(x)\n",
    "    x = Conv2D(64, kernel_size=3, strides=1, activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(model_param.node_num, activation='relu')(x)\n",
    "\n",
    "    out_values = Dense(model_param.value_size, activation='linear', name='output')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_states], outputs=[out_values])\n",
    "    model.compile(optimizer=Adam(learning_rate=model_param.learning_rate_critic),\n",
    "                  loss='mean_squared_error')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def norm(pointA, pointB):\n",
    "    return np.sqrt((pointA[0] - pointB[0])**2 + (pointA[1] - pointB[1])**2 + (pointA[2] - pointB[2])**2)\n",
    "\n",
    "def get_state(prv_states):\n",
    "    # init states[4]\n",
    "    dt = 1/240\n",
    "    states = np.zeros(4)\n",
    "    target_position = specimen_position+ring_offset\n",
    "    #print(target_position)\n",
    "    end_effector_position = tool.get_tool_pose()[0]+np.array([0.135,0,0])\n",
    "    #print(end_effector_position)\n",
    "    end_effector_orientation = p.getEulerFromQuaternion(tool.get_tool_pose()[1]) + np.array([-np.pi/2,0,-np.pi/2])\n",
    "    states[0] = norm(end_effector_position,target_position) # pos diff\n",
    "    states[1] = (prv_states[0]-states[0])/dt # velocity\n",
    "    states[2] = norm(end_effector_orientation,specimen_orientation_euler)# angle diff\n",
    "    states[3] = (prv_states[2]-states[2])/dt # angular velocity\n",
    "    #print states in a row\n",
    "    print(\"pos diff: \",states[0],\" velocity: \",states[1],\" angle diff: \",states[2],\" angular velocity: \",states[3])\n",
    "    print(\"angle: \",end_effector_orientation, \"angle_specimen\"  ,specimen_orientation_euler)\n",
    "    return states\n",
    "\n",
    "def train(model_param):\n",
    "    for episode in range(model_param.episode_num):\n",
    "        initialize()\n",
    "        model_param.states = np.zeros(4)\n",
    "        model_param.states = get_state(model_param.states)\n",
    "        count, reward_tot = make_memory(model_param)\n",
    "\n",
    "def make_memory(model_param):\n",
    "        reward_tot = 0\n",
    "        count = 0\n",
    "        reward = np.zeros(model_param.value_size)\n",
    "        #advantage = np.zeros(model_param.value_size)\n",
    "        #target = np.zeros(model_param.value_size)\n",
    "        action_matrix = np.zeros(model_param.action_size)\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            count+=1\n",
    "\n",
    "            #state_t = np.reshape(state,[1, 1, model_param.state_size])\n",
    "            #action_matrix_t = np.reshape(action_matrix,[1, 1, model_param.action_size])\n",
    "\n",
    "            # 1. take a picture\n",
    "            img = camera.get_image() # now img is the state\n",
    "            img_uint8 = img.astype(np.uint8)\n",
    "            rgb = img_uint8[:,:,:3]\n",
    "            rgb = np.expand_dims(rgb, axis=0)\n",
    "            \n",
    "            # 2. calculate probabilty and predict action\n",
    "            action_prob = model_param.model_actor.predict([rgb, model_param.DUMMY_ACTION_MATRIX, model_param.DUMMY_ADVANTAGE])\n",
    "            action = np.random.choice(model_param.action_size, 1, p=action_prob[0][0])[0]\n",
    "            action_matrix = np.zeros(model_param.action_size) #초기화\n",
    "            action_matrix[action] = 1\n",
    "\n",
    "            # 3. move\n",
    "\n",
    "            # 4. calculate reward\n",
    "\n",
    "            # 5. judge if finished or not\n",
    "\n",
    "\n",
    "\n",
    "            state_next, reward, done, none, none2 = model_param.env.step(action)\n",
    "            \n",
    "            state_next_t = np.reshape(state_next,[1, 1, model_param.state_size])\n",
    "            \n",
    "            if count < 500 and done:\n",
    "                reward = model_param.penalty \n",
    "        \n",
    "            model_param.states.append(np.reshape(state_t, [1,model_param.state_size]))\n",
    "            model_param.states_next.append(np.reshape(state_next_t, [1,model_param.state_size]))\n",
    "            model_param.action_matrixs.append(np.reshape(action_matrix, [1,model_param.action_size]))\n",
    "            model_param.dones.append(np.reshape(0 if done else 1, [1,model_param.value_size]))\n",
    "            model_param.action_probs.append(np.reshape(action_prob, [1,model_param.action_size]))\n",
    "            model_param.rewards.append(np.reshape(reward, [1,model_param.value_size]))\n",
    "            \n",
    "            if(count % model_param.mini_batch_step_size == 0):\n",
    "                model_param.train_mini_batch()\n",
    "                model_param.clear_memory()\n",
    "\n",
    "            reward_tot += reward\n",
    "            state = state_next\n",
    "            \n",
    "        return count, reward_tot\n",
    "\n",
    "\n",
    "model_param = AI_init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0656309e-24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(action_prob[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_model_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_model_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_states        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> │ input_states[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_action_matri… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_advantages    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_states        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │        \u001b[38;5;34m120\u001b[0m │ input_states[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_action_matri… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_advantages    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │         \u001b[38;5;34m50\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> (680.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m170\u001b[0m (680.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> (680.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m170\u001b[0m (680.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_states (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_states (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m24\u001b[0m)          │           \u001b[38;5;34m120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │            \u001b[38;5;34m25\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">145</span> (580.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m145\u001b[0m (580.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">145</span> (580.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m145\u001b[0m (580.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool8'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 203\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    202\u001b[0m     agent \u001b[38;5;241m=\u001b[39m Agent()\n\u001b[1;32m--> 203\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 93\u001b[0m, in \u001b[0;36mAgent.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m state \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mmax_episode_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m---> 93\u001b[0m count, reward_tot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_mini_batch()\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_memory()\n",
      "Cell \u001b[1;32mIn[29], line 129\u001b[0m, in \u001b[0;36mAgent.make_memory\u001b[1;34m(self, episode, state)\u001b[0m\n\u001b[0;32m    126\u001b[0m action_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_size) \u001b[38;5;66;03m#초기화\u001b[39;00m\n\u001b[0;32m    127\u001b[0m action_matrix[action] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 129\u001b[0m state_next, reward, done, none, none2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m state_next_t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(state_next,[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_size])\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m done:\n",
      "File \u001b[1;32mc:\\Users\\b34b3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gym\\wrappers\\time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\b34b3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\b34b3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gym\\wrappers\\env_checker.py:37\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\b34b3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[1;34m(env, action)\u001b[0m\n\u001b[0;32m    230\u001b[0m obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# np.bool is actual python bool not np boolean type, therefore bool_ or bool8\u001b[39;00m\n\u001b[1;32m--> 233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(terminated, (\u001b[38;5;28mbool\u001b[39m, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool8\u001b[49m)):\n\u001b[0;32m    234\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpects `terminated` signal to be a boolean, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(terminated)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m     )\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncated, (\u001b[38;5;28mbool\u001b[39m, np\u001b[38;5;241m.\u001b[39mbool8)):\n",
      "File \u001b[1;32mc:\\Users\\b34b3\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\__init__.py:424\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[1;32m--> 424\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    425\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool8'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.client import device_lib\n",
    "import gym\n",
    "import numpy as np\n",
    "import random as rand\n",
    "\n",
    "LOSS_CLIPPING = 0.2\n",
    "class Agent(object):\n",
    "    def __init__(self):\n",
    "        self.env = gym.make('CartPole-v1')\n",
    "        self.state_size = self.env.observation_space.shape[0]\n",
    "        self.action_size = self.env.action_space.n\n",
    "        self.value_size = 1\n",
    "        \n",
    "        self.node_num = 24\n",
    "        self.learning_rate_actor = 0.0005\n",
    "        self.learning_rate_critic = 0.0005\n",
    "        self.epochs_cnt = 5\n",
    "        self.model_actor = self.build_model_actor()\n",
    "        self.model_critic = self.build_model_critic()\n",
    "        \n",
    "        self.discount_rate = 0.98\n",
    "        self.smooth_rate = 0.95\n",
    "        self.penalty = -400\n",
    "        \n",
    "        self.episode_num = 500\n",
    "        self.mini_batch_step_size = 32        \n",
    "        \n",
    "        self.moving_avg_size = 20\n",
    "        self.reward_list= []\n",
    "        self.count_list = []\n",
    "        self.moving_avg_list = []\n",
    "        \n",
    "        self.states, self.states_next, self.action_matrixs = [],[],[]\n",
    "        self.dones, self.action_probs, self.rewards = [],[],[]\n",
    "        self.DUMMY_ACTION_MATRIX = np.zeros((1,1,self.action_size))\n",
    "        self.DUMMY_ADVANTAGE = np.zeros((1,1,self.value_size))\n",
    "        \n",
    "    class MyModel(tf.keras.Model):\n",
    "        def train_step(self, data):\n",
    "            in_datas, out_action_probs = data\n",
    "            states, action_matrixs, advantages = in_datas[0], in_datas[1], in_datas[2]\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = self(states, training=True)\n",
    "                new_policy = K.max(action_matrixs*y_pred, axis=-1)   \n",
    "                old_policy = K.max(action_matrixs*out_action_probs, axis=-1)   \n",
    "                r = new_policy/(old_policy)\n",
    "                clipped = K.clip(r, 1-LOSS_CLIPPING, 1+LOSS_CLIPPING)\n",
    "                loss = -K.minimum(r*advantages, clipped*advantages)\n",
    "            \n",
    "            trainable_vars = self.trainable_variables\n",
    "            gradients = tape.gradient(loss, trainable_vars)\n",
    "            self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "            \n",
    "    def build_model_actor(self):\n",
    "        input_states = Input(shape=(1,self.state_size), name='input_states')\n",
    "        input_action_matrixs = Input(shape=(1,self.action_size), name='input_action_matrixs')\n",
    "        input_advantages = Input(shape=(1,self.value_size), name='input_advantages')\n",
    "\n",
    "        x = (input_states)\n",
    "        x = Dense(self.node_num, activation='relu')(x)\n",
    "        out_actions = Dense(self.action_size, activation='softmax', name='output')(x)\n",
    "        \n",
    "        model = self.MyModel(inputs=[input_states, input_action_matrixs, input_advantages], outputs=out_actions)\n",
    "        model.compile(optimizer=Adam(learning_rate=self.learning_rate_actor))\n",
    "        \n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    def build_model_critic(self):\n",
    "        input_states = Input(shape=(1,self.state_size), name='input_states')\n",
    "        x = (input_states)\n",
    "        x = Dense(self.node_num, activation='relu')(x)\n",
    "        out_values = Dense(self.value_size, activation='linear', name='output')(x)\n",
    "        \n",
    "        model = tf.keras.models.Model(inputs=[input_states], outputs=[out_values])\n",
    "        model.compile(optimizer=Adam(learning_rate=self.learning_rate_critic),\n",
    "                      loss='mean_squared_error'\n",
    "                     )\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        for episode in range(self.episode_num):\n",
    "\n",
    "            state = self.env.reset()\n",
    "            state = state[0]\n",
    "            self.env.max_episode_steps = 500\n",
    "\n",
    "            count, reward_tot = self.make_memory(episode, state)\n",
    "            self.train_mini_batch()\n",
    "            self.clear_memory()\n",
    "            \n",
    "            if count < 500:\n",
    "                reward_tot = reward_tot-self.penalty\n",
    "                \n",
    "            self.reward_list.append(reward_tot)\n",
    "            self.count_list.append(count)\n",
    "            self.moving_avg_list.append(self.moving_avg(self.count_list,self.moving_avg_size))                \n",
    "            \n",
    "            if(episode % 10 == 0):\n",
    "                print(\"episode:{}, moving_avg:{}, rewards_avg:{}\".format(episode, self.moving_avg_list[-1], np.mean(self.reward_list)))\n",
    "        self.save_model()\n",
    "        \n",
    "    def make_memory(self, episode, state):\n",
    "        reward_tot = 0\n",
    "        count = 0\n",
    "        reward = np.zeros(self.value_size)\n",
    "        advantage = np.zeros(self.value_size)\n",
    "        target = np.zeros(self.value_size)\n",
    "        action_matrix = np.zeros(self.action_size)\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            count+=1\n",
    "\n",
    "            state_t = np.reshape(state,[1, 1, self.state_size])\n",
    "            action_matrix_t = np.reshape(action_matrix,[1, 1, self.action_size])\n",
    "            \n",
    "            action_prob = self.model_actor.predict([state_t, self.DUMMY_ACTION_MATRIX, self.DUMMY_ADVANTAGE])\n",
    "\n",
    "            action = np.random.choice(self.action_size, 1, p=action_prob[0][0])[0]\n",
    "            action_matrix = np.zeros(self.action_size) #초기화\n",
    "            action_matrix[action] = 1\n",
    "\n",
    "            state_next, reward, done, none, none2 = self.env.step(action)\n",
    "            \n",
    "            state_next_t = np.reshape(state_next,[1, 1, self.state_size])\n",
    "            \n",
    "            if count < 500 and done:\n",
    "                reward = self.penalty \n",
    "        \n",
    "            self.states.append(np.reshape(state_t, [1,self.state_size]))\n",
    "            self.states_next.append(np.reshape(state_next_t, [1,self.state_size]))\n",
    "            self.action_matrixs.append(np.reshape(action_matrix, [1,self.action_size]))\n",
    "            self.dones.append(np.reshape(0 if done else 1, [1,self.value_size]))\n",
    "            self.action_probs.append(np.reshape(action_prob, [1,self.action_size]))\n",
    "            self.rewards.append(np.reshape(reward, [1,self.value_size]))\n",
    "            \n",
    "            if(count % self.mini_batch_step_size == 0):\n",
    "                self.train_mini_batch()\n",
    "                self.clear_memory()\n",
    "\n",
    "            reward_tot += reward\n",
    "            state = state_next\n",
    "            \n",
    "        return count, reward_tot\n",
    "        \n",
    "    def make_gae(self, values, values_next, rewards, dones):\n",
    "        delta_adv, delta_tar, adv, target = 0, 0, 0, 0\n",
    "        advantages = np.zeros(np.array(values).shape)\n",
    "        targets = np.zeros(np.array(values).shape)\n",
    "        for t in reversed(range(0, len(rewards))):\n",
    "            delta_adv = rewards[t] + self.discount_rate * values_next[t] * dones[t] - values[t]\n",
    "            delta_tar = rewards[t] + self.discount_rate * values_next[t] * dones[t]\n",
    "            adv = delta_adv + self.smooth_rate*self.discount_rate * dones[t] * adv\n",
    "            target = delta_tar + self.smooth_rate*self.discount_rate * dones[t] * target\n",
    "            advantages[t] = adv\n",
    "            targets[t] = target\n",
    "        return advantages, targets\n",
    "\n",
    "    def train_mini_batch(self):\n",
    "        \n",
    "        if len(self.states) == 0:\n",
    "            return\n",
    "        \n",
    "        states_t = np.array(self.states)\n",
    "        states_next_t = np.array(self.states_next)\n",
    "        action_matrixs_t = np.array(self.action_matrixs)\n",
    "        action_probs_t = np.array(self.action_probs)\n",
    "        rewards_t = np.array(self.rewards)\n",
    "\n",
    "        values = self.model_critic.predict(states_t)\n",
    "        values_next = self.model_critic.predict(states_next_t)\n",
    "        \n",
    "        advantages, targets = self.make_gae(values, values_next, self.rewards, self.dones)\n",
    "        advantages_t = np.array(advantages)\n",
    "        targets_t = np.array(targets)\n",
    "\n",
    "        self.model_actor.fit([states_t, action_matrixs_t, advantages_t], [action_probs_t], epochs=self.epochs_cnt, verbose=0)\n",
    "        self.model_critic.fit(states_t, targets_t, epochs=self.epochs_cnt, verbose=0)       \n",
    " \n",
    "    def clear_memory(self):\n",
    "        self.states, self.states_next, self.action_matrixs = [],[],[]\n",
    "        self.dones, self.action_probs, self.rewards = [],[],[]\n",
    "        \n",
    "    def moving_avg(self, data, size=10):\n",
    "        if len(data) > size:\n",
    "            c = np.array(data[len(data)-size:len(data)]) \n",
    "        else:\n",
    "            c = np.array(data) \n",
    "        return np.mean(c)\n",
    "    \n",
    "    def save_model(self):\n",
    "        self.model_actor.save(\"./model/ppo\")\n",
    "        print(\"*****end learing\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent = Agent()\n",
    "    agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "env.observation_space.shape[0] # 위치, 속도, 각도, 각속도?\n",
    "env.action_space.n # 좌우 2개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distance between pointA and pointB (3dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos diff:  0.16357298126706452  velocity:  0.0  angle diff:  0.02465193761612129  angular velocity:  0.0\n",
      "angle:  [-0.02178325 -0.01130558 -0.00232204] angle_specimen [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "if 'state' not in locals():\n",
    "    state =np.zeros(4)\n",
    "\n",
    "state = get_state(state)\n",
    "\n",
    "\n",
    "# if variable state does not exsit\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
